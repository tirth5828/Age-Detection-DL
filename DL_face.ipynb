{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOCUEqILkgdg/o9xjMC5x6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirth5828/Age-Detection-DL/blob/main/DL_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7rxFFPcysYDf"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
        "from keras.layers import Conv2D, AveragePooling2D\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import metrics\n",
        "\n",
        "from keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "import cv2\n",
        "\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMPEov1vHRla",
        "outputId": "7ecefed8-2321-4539-89c0-4606fb7d538a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory = '/content/drive/My Drive/data'\n",
        "\n",
        "image_size = 100\n",
        "classes = 101\n",
        "\n",
        "# #age groups\n",
        "# age_ranges = {\n",
        "#     (6,20) : 0, \n",
        "#     (35,40) : 1, \n",
        "#     (55,98) : 2\n",
        "# }\n",
        "\n",
        "#age groups\n",
        "age_ranges = {\n",
        "    (0,27) : 0, \n",
        "    (28,47) : 1, \n",
        "    (48,100) : 2\n",
        "}\n",
        "\n",
        "# convert age to age group\n",
        "def convert_ranges(age):\n",
        "  for key in age_ranges:\n",
        "    if key[0] <= age <= key[1]:\n",
        "      return age_ranges[key]\n",
        "\n",
        "# transform labels to age\n",
        "def transform_labels_age(labels_vec):\n",
        "  new_labels_vec = []\n",
        "  for x in labels_vec:\n",
        "    x2 = x.split('-')\n",
        "    new_labels_vec.append(convert_ranges(int(x2[1])))\n",
        "  return np.array(new_labels_vec)\n",
        "\n",
        "# transform labels to index\n",
        "def transform_labels_index(labels_vec):\n",
        "  new_labels_vec = []\n",
        "  for x in labels_vec:\n",
        "    x2 = x.split('-')\n",
        "    new_labels_vec.append(convert_ranges(int(x2[0])))\n",
        "  return np.array(new_labels_vec)"
      ],
      "metadata": {
        "id": "1J6isdARG9dR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train dataset\n",
        "# set of data to be used for learning\n",
        "images_train = np.load(join(dataset_directory, 'train_images.npy'))\n",
        "print(images_train.shape)\n",
        "\n",
        "# load train dataset labels\n",
        "labels_train_full = np.load(join(dataset_directory, 'train_labels.npy'))\n",
        "\n",
        "# transform trains dataset labels....................................................................................\n",
        "labels_train = transform_labels_age(labels_train_full)\n",
        "\n",
        "# load valid dataset\n",
        "# set of data to be used to provide an unbiased evaluation of the model fitted on the the training dataset while tuning model hyperparameters\n",
        "images_val = np.load(join(dataset_directory, 'val_images.npy'))\n",
        "\n",
        "# load valid dataset labels\n",
        "labels_val_full = np.load(join(dataset_directory, 'val_labels.npy'))\n",
        "\n",
        "# transmiform valid dataset labels....................................................................................\n",
        "labels_val = transform_labels_age(labels_val_full)\n",
        "\n",
        "# load test dataset(public)\n",
        "# set of data to be used to provide an unbiased evaluation of the final model fitted on the training dataset\n",
        "images_test_public = np.load(join(dataset_directory, 'test_images.npy'))\n",
        "\n",
        "# reshape datasets (normalisation)\n",
        "images_train = images_train.reshape([-1, image_size, image_size, 3]) / 255.0\n",
        "images_val = images_val.reshape([-1, image_size, image_size, 3]) / 255.0\n",
        "images_test_public = images_test_public.reshape([-1, image_size, image_size, 3]) / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "uJeMqtiYHODk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7feafed-777a-46e0-aba8-8728b59f1979"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13475, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_val = transform_labels_index(labels_val_full)"
      ],
      "metadata": {
        "id": "pHtv84BMuasQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_train.shape)\n",
        "print(images_val.shape)\n",
        "print(images_test_public.shape)\n",
        "\n",
        "print(labels_train_full[:9])\n",
        "print(labels_train[:9])\n",
        "\n",
        "print(labels_val_full[:9])\n",
        "print(labels_val[:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og0k3_sHHYc-",
        "outputId": "b2b0e0a6-d962-46b3-9e7d-81d069773559"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13475, 100, 100, 3)\n",
            "(2595, 100, 100, 3)\n",
            "(2374, 100, 100, 3)\n",
            "['12466-81' '12466-61' '12466-81' '12466-61' '12566-35' '12566-37'\n",
            " '12566-35' '12566-35' '12566-37']\n",
            "[2 2 2 2 1 1 1 1 1]\n",
            "['12626-16' '12726-37' '12726-37' '12726-37' '12726-37' '12726-37'\n",
            " '12726-37' '12726-39' '12726-37']\n",
            "[0 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bar(y, loc='left', relative=True):\n",
        "    width = 0.35\n",
        "    if loc == 'left':\n",
        "        n = -0.5\n",
        "    elif loc == 'right':\n",
        "        n = 0.5\n",
        "     \n",
        "    # calculate counts per type and sort, to ensure their order\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    sorted_index = np.argsort(unique)\n",
        "    unique = unique[sorted_index]\n",
        "     \n",
        "    if relative:\n",
        "        # plot as a percentage\n",
        "        counts = 100*counts[sorted_index]/len(y)\n",
        "        ylabel_text = '% count'\n",
        "    else:\n",
        "        # plot counts\n",
        "        counts = counts[sorted_index]\n",
        "        ylabel_text = 'count'\n",
        "         \n",
        "    xtemp = np.arange(len(unique))\n",
        "     \n",
        "    plt.bar(xtemp + n*width, counts, align='center', alpha=.7, width=width)\n",
        "    plt.xticks(xtemp, unique, rotation=45)\n",
        "    plt.xlabel('age group')\n",
        "    plt.ylabel(ylabel_text)\n",
        " \n",
        "plt.suptitle('relative amount of image per age group')\n",
        "plot_bar(labels_train, loc='left')\n",
        "plot_bar(labels_val, loc='right')\n",
        "plt.legend([\n",
        "    'images_train ({0})'.format(len(labels_train)), \n",
        "    'images_val ({0})'.format(len(labels_val))\n",
        "]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "1nTLZhW4HWvT",
        "outputId": "ba013398-2b89-4726-dd64-2b900f2b22f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG-Face model\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(2622, (1, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "VRwCGE4MJ2SO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = \"/content/drive/MyDrive/vgg_face_weights.h5\""
      ],
      "metadata": {
        "id": "78FMmYiEN0h2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(weights)"
      ],
      "metadata": {
        "id": "ovFa3_cOVi64"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-7]:\n",
        "    layer.trainable = False\n",
        "\n",
        "base_model_output = Sequential()\n",
        "base_model_output = Convolution2D(classes, (1, 1), name='predictions')(model.layers[-4].output)\n",
        "base_model_output = Flatten()(base_model_output)\n",
        "base_model_output = Activation('softmax')(base_model_output)\n",
        "\n",
        "age_model = Model(inputs=model.input, outputs=base_model_output)"
      ],
      "metadata": {
        "id": "aDnTaK9lVqAd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "    for layer in model.layers:\n",
        "        print(layer, layer.trainable)\n",
        "    \n",
        "    print(\"------------------------\")\n",
        "    for layer in age_model.layers:\n",
        "        print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "N4N5QNavVsNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "age_model.compile(loss='categorical_crossentropy'\n",
        "                  , optimizer=keras.optimizers.Adam()\n",
        "                  #, optimizer = sgd\n",
        "                  , metrics=['accuracy']\n",
        "                 )"
      ],
      "metadata": {
        "id": "D_mlvX8L1QD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a73356-426c-4ead-951d-e77e5f81ecd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(\n",
        "    filepath='classification_age_model.hdf5'\n",
        "    , monitor = \"val_loss\"\n",
        "    , verbose=1\n",
        "    , save_best_only=True\n",
        "    , mode = 'auto'\n",
        ")"
      ],
      "metadata": {
        "id": "aF8M_2au1QSY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []"
      ],
      "metadata": {
        "id": "TSfg8U0z9JG5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enableFit = False\n",
        "\n",
        "if enableFit:\n",
        "    epochs = 250\n",
        "    batch_size = 256\n",
        "\n",
        "    for i in range(epochs):\n",
        "        print(\"epoch \",i)\n",
        "        \n",
        "        ix_train = np.random.choice(images_train.shape[0], size=batch_size)\n",
        "\n",
        "\n",
        "        \n",
        "        score = age_model.fit(\n",
        "            images_train[ix_train], images_val[ix_train]\n",
        "            , epochs=1\n",
        "            , validation_data=(labels_train, labels_val)\n",
        "            , callbacks=[checkpointer]\n",
        "        )\n",
        "        \n",
        "        scores.append(score)\n",
        "    \n",
        "    #restore the best weights\n",
        "    from keras.models import load_model\n",
        "    age_model = load_model(\"classification_age_model.hdf5\")\n",
        "    \n",
        "    age_model.save_weights('age_model_weights.h5')\n",
        "        \n",
        "else:\n",
        "    #pre-trained weights for age prediction: https://drive.google.com/file/d/1YCox_4kJ-BYeXq27uUbasu--yz28zUMV/view?usp=sharing\n",
        "    age_model.load_weights(\"/content/drive/MyDrive/age_model_weights.h5\")"
      ],
      "metadata": {
        "id": "XfNGaBmo9OCQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_change = []; loss_change = []\n",
        "for i in range(0, len(scores)):\n",
        "    val_loss_change.append(scores[i].history['val_loss'])\n",
        "    loss_change.append(scores[i].history['loss'])\n",
        "\n",
        "plt.plot(val_loss_change, label='val_loss')\n",
        "plt.plot(loss_change, label='train_loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EFjIF_KEtecw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(predection):\n",
        "  output = []\n",
        "  for i in predection:\n",
        "    max = -1\n",
        "    max_id = -1\n",
        "    for i,val in enumerate(i): \n",
        "      if val>max:\n",
        "        max = val\n",
        "        max_id = i\n",
        "    output.append(convert_ranges(max_id + 1))\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "9KGkABS_5_kq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_labels = []"
      ],
      "metadata": {
        "id": "7V4GLWNdK_Lq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_images_test_public = []\n",
        "\n",
        "threshold = 50\n",
        "\n",
        "for i,image in enumerate(images_test_public):\n",
        "  if (i%threshold == 0 or i == len(images_test_public) - 1) and (i!=0):\n",
        "    resize_images_test_public = np.array(resize_images_test_public[:])\n",
        "    predictions = age_model.predict(resize_images_test_public)\n",
        "    output_labels.extend(get_label(predictions))\n",
        "    resize_images_test_public = []\n",
        "  resize_images_test_public.append(cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiiw_-plt0wf",
        "outputId": "b5967c3c-efc2-4987-96ff-b89382d18aea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 27s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 27s 10s/step\n",
            "2/2 [==============================] - 29s 11s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 10s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 28s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "2/2 [==============================] - 26s 9s/step\n",
            "1/1 [==============================] - 12s 12s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.DataFrame(output_labels)\n",
        "df.index.name='ID'\n",
        "os.chdir('/content/drive/My Drive/results')\n",
        "\n",
        "currentDateTime = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
        "\n",
        "#df.to_csv(f'45892342-conv-{currentDateTime}.csv', header=['Prediction'])\n",
        "df.to_csv(f'45892342-nconv-CNN.csv', header=['Prediction'])"
      ],
      "metadata": {
        "id": "QpjvBCkvDgJ1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mz6iMpStn6s5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}